{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b3214d",
   "metadata": {},
   "source": [
    "# 深度学习动手实验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30384c",
   "metadata": {},
   "source": [
    "## 任务介绍——语义分割\n",
    "\n",
    "语义分割是当今计算机视觉领域的关键问题之一。从宏观上看，语义分割是一项高层次的任务，为实现场景的完整理解铺平了道路。场景理解作为一个核心的计算机视觉问题，其重要性在于越来越多的应用程序通过从图像中推断知识来提供营养。其中一些应用包括自动驾驶汽车、人机交互、虚拟现实等，近年来随着深度学习的普及，许多语义分割问题正在采用深层次的结构来解决，最常见的是卷积神经网络，在精度上大大超过了其他方法。以及效率。\n",
    "\n",
    "![1](./Photos/seg1.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de2f84",
   "metadata": {},
   "source": [
    "## 神经网络\n",
    "\n",
    "### Encoder-Decoder\n",
    "\n",
    "![1](./Photos/ed.jpeg)\n",
    "\n",
    "### UNet\n",
    "\n",
    "![2](./Photos/unet.jpeg)\n",
    "\n",
    "### UNet++\n",
    "\n",
    "![3](./Photos/unetpp.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1040fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c453a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class unetpp(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.conv_00 = DoubleConvLayers(in_channel, 64)\n",
    "        self.conv_10 = DoubleConvLayers(64, 64)\n",
    "        self.conv_20 = DoubleConvLayers(64, 64)\n",
    "        self.conv_30 = DoubleConvLayers(64, 64)\n",
    "        self.conv_01 = DoubleConvLayers(128, 64)\n",
    "        self.conv_11 = DoubleConvLayers(128, 64)\n",
    "        self.conv_21 = DoubleConvLayers(128, 64)\n",
    "        self.conv_02 = DoubleConvLayers(192, 64)\n",
    "        self.conv_12 = DoubleConvLayers(192, 64)\n",
    "        self.conv_03 = DoubleConvLayers(256, 64)\n",
    "        self.down_00 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.down_10 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.down_20 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.up_00 = nn.Upsample(scale_factor=2)\n",
    "        self.up_10 = nn.Upsample(scale_factor=2)\n",
    "        self.up_20 = nn.Upsample(scale_factor=2)\n",
    "        self.up_01 = nn.Upsample(scale_factor=2)\n",
    "        self.up_11 = nn.Upsample(scale_factor=2)\n",
    "        self.up_02 = nn.Upsample(scale_factor=2)\n",
    "        self.conv_l1 = nn.Conv2d(64, out_channel, kernel_size=1, padding=0)\n",
    "        self.conv_l2 = nn.Conv2d(64, out_channel, kernel_size=1, padding=0)\n",
    "        self.conv_l3 = nn.Conv2d(64, out_channel, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_00 = self.conv_00(x)\n",
    "        down_00 = self.down_00(x_00)\n",
    "        x_10 = self.conv_10(down_00)\n",
    "        down_10 = self.down_10(x_10)\n",
    "        x_20 = self.conv_20(down_10)\n",
    "        down_20 = self.down_20(x_20)\n",
    "        x_30 = self.conv_30(down_20)\n",
    "\n",
    "        up_00 = self.up_00(x_10)\n",
    "        up_10 = self.up_10(x_20)\n",
    "        up_20 = self.up_20(x_30)\n",
    "\n",
    "        x_01 = self.conv_01(torch.cat([x_00, up_00], dim=1))\n",
    "        x_11 = self.conv_11(torch.cat([x_10, up_10], dim=1))\n",
    "        x_21 = self.conv_21(torch.cat([x_20, up_20], dim=1))\n",
    "\n",
    "        up_01 = self.up_01(x_11)\n",
    "        up_11 = self.up_11(x_21)\n",
    "\n",
    "        x_02 = self.conv_02(torch.cat([x_00, x_01, up_01], dim=1))\n",
    "        x_12 = self.conv_12(torch.cat([x_10, x_11, up_11], dim=1))\n",
    "\n",
    "        up_02 = self.up_02(x_12)\n",
    "\n",
    "        x_03 = self.conv_03(torch.cat([x_00, x_01, x_02, up_02], dim=1))\n",
    "\n",
    "        l1 = self.conv_l1(x_01)\n",
    "        l2 = self.conv_l2(x_02)\n",
    "        l3 = self.conv_l3(x_03)\n",
    "\n",
    "        return (l1 + l2 + l3) / 3\n",
    "\n",
    "\n",
    "class DoubleConvLayers(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.ConvLayers = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ConvLayers(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.MaxPoolConv = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            DoubleConvLayers(in_channel, out_channel)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.MaxPoolConv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.UpSample = nn.Upsample(scale_factor=2)\n",
    "        self.ConvLayers = DoubleConvLayers(in_channel, out_channel)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.UpSample(x1)\n",
    "        return self.ConvLayers(torch.cat([x1, x2], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "056b6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC数据集的标注为边缘线框，UNet训练效果不理想，建议替换为其他数据集\n",
    "class train():\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.batch_size = 1 # 每一轮训练的数据量\n",
    "        self.num_workers = 1 # 参与数据准备的核心数\n",
    "        self.shuffle = True # 随机打乱数据集\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 训练部署在CPU或者GPU\n",
    "        self.net = unetpp(in_channel=3, out_channel=2)\n",
    "        self.net.to(self.device)\n",
    "        \n",
    "        self.tf = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        \n",
    "        # VOC\n",
    "        train_dataset = datasets.VOCSegmentation(root='./Dataset', year='2007', image_set='train', download=True, transform=self.tf, target_transform=self.tf)\n",
    "        valid_dataset = datasets.VOCSegmentation(root='./Dataset', year='2007', image_set='val', download=True, transform=self.tf, target_transform=self.tf)\n",
    "\n",
    "        \n",
    "        self.train_dataset_loader = DataLoader(train_dataset, shuffle=self.shuffle, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "        self.valid_dataset_loader = DataLoader(valid_dataset, shuffle=self.shuffle, batch_size=1, num_workers=1)\n",
    "\n",
    "    def save(self):\n",
    "        torch.save(self.net.state_dict(), './Model/clf_network.pth')\n",
    "\n",
    "    def load(self):\n",
    "        self.net.load_state_dict(torch.load('./Model/clf_network.pth', map_location='cpu'))\n",
    "        self.net.to(self.device)\n",
    "\n",
    "    def train_net(self):\n",
    "        \n",
    "        self.net.train()\n",
    "        epoch_n, epoch_loss = 0, 0.0\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=0.001)\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        for img, true_target in self.train_dataset_loader:\n",
    "            img = img.to(self.device).float()\n",
    "            true_target = true_target.to(self.device)\n",
    "            fake_target = self.net(img)\n",
    "            true_target = true_target.squeeze().long()\n",
    "            loss = loss_func(fake_target, true_target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_loss = loss.detach().cpu().numpy()\n",
    "            epoch_n = epoch_n + int(img.shape[0])\n",
    "            epoch_loss = epoch_loss + batch_loss\n",
    "            \n",
    "        epoch_loss = epoch_loss / epoch_n\n",
    "        \n",
    "        print(\"**********\")\n",
    "        print(\"task in train\")\n",
    "        print(\"epoch_n = \" + str(epoch_n))\n",
    "        print(\"epoch_loss = \" + str(epoch_loss))\n",
    "        print(\"**********\")\n",
    "            \n",
    "    def valid_net(self):\n",
    "    \n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            for img, true_target in self.valid_dataset_loader:\n",
    "                img = img.to(self.device).float()\n",
    "                fake_target = self.net(img)\n",
    "                \n",
    "                true_target = true_target.detach().cpu().numpy()[0]\n",
    "                fake_target = fake_target.detach().cpu().numpy()[0]\n",
    "                \n",
    "                true_target = true_target[0]\n",
    "                fake_target = fake_target.argmax(axis=0)\n",
    "                \n",
    "#                 true_target = true_target.astype(np.int64)\n",
    "#                 fake_target = fake_target.astype(np.int64)\n",
    "                \n",
    "#                 true_target = cv.cvtColor(true_target, cv.COLOR_GRAY2BGR)\n",
    "                \n",
    "#                 cv.imshow('true_target', true_target*200)\n",
    "#                 cv.imshow('fake_target', fake_target*200)\n",
    "#                 cv.waitKey(1000)\n",
    "#                 plt.figure()\n",
    "                plt.clf()\n",
    "                plt.figure()\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(true_target*255, cmap='gray')\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.imshow(fake_target*255, cmap='gray')\n",
    "                plt.show()\n",
    "                input('Continue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a49d3",
   "metadata": {},
   "source": [
    "### 心脏超声图像分割案例\n",
    "\n",
    "![1](./Photos/ultrasound.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589b765",
   "metadata": {},
   "source": [
    "## 任务介绍——目标检测\n",
    "\n",
    "目标检测（Object Detection）的任务是找出图像中所有感兴趣的目标（物体），确定它们的类别和位置，是计算机视觉领域的核心问题之一。由于各类物体有不同的外观、形状和姿态，加上成像时光照、遮挡等因素的干扰，目标检测一直是计算机视觉领域最具有挑战性的问题。\n",
    "![1](./Photos/detach1.jpeg)\n",
    "\n",
    "### 核心问题\n",
    "1. 分类问题：即图片（或某个区域）中的图像属于哪个类别。\n",
    "2. 定位问题：目标可能出现在图像的任何位置。\n",
    "3. 大小问题：目标有各种不同的大小。\n",
    "4. 形状问题：目标可能有各种不同的形状。\n",
    "![2](./Photos/detach2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a07d6b",
   "metadata": {},
   "source": [
    "### R-CNN\n",
    "\n",
    "R-CNN作者受AlexNet启发，尝试将图像分类迁移到PASCAL VOC的目标检测上。R-CNN利用候选区域的方法（Region Proposal），这也是该网络被称为R-CNN的原因：Regions with CNN features。对于小规模数据集的问题，R-CNN使用了微调的方法。并利用ImageNet对AlexNet预训练。\n",
    "\n",
    "R-CNN目标检测的思路：\n",
    "- 给定一张图片，从图片中选出2000个独立的候选区域(Region Proposal)\n",
    "- 将每个候选区域输入到预训练好的AlexNet中，提取一个固定长度（4096）的特征向量\n",
    "- 对每个目标（类别）训练一SVM分类器，识别该区域是否包含目标\n",
    "- 训练一个回归器，修正候选区域中目标的位置：对于每个类，训练一个线性回归模型判断当前框是不是很完美。\n",
    "![1](./Photos/rcnn.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ff7e39",
   "metadata": {},
   "source": [
    "### YOLO\n",
    "\n",
    "Yolo的将输入的图片分割成若干个网格，然后每个单元格负责去检测那些中心点落在该格子内的目标。目标的标签为（x, y, w, h, c），其中c为置信度）。\n",
    "![1](./Photos/yolo1.jpeg)\n",
    "\n",
    "Yolo采用卷积网络来提取特征，然后使用全连接层来得到预测值。网络结构参考GooLeNet模型，包含24个卷积层和2个全连接层。对于卷积层，主要使用1x1卷积来做通道压缩，然后紧跟3x3卷积。对于卷积层和全连接层，采用Leaky ReLU激活函数。但是最后一层却采用线性激活函数。\n",
    "![2](./Photos/yolo2.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a8245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
